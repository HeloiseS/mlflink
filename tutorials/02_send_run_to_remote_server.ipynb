{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial 2: Sending Selected Runs to Remote Server\n",
        "\n",
        "## 🎯 Learning Objectives\n",
        "\n",
        "By the end of this tutorial, you will:\n",
        "- Understand how to identify your best local runs\n",
        "- Learn to retrieve artifacts from local MLflow runs\n",
        "- Master the process of re-running experiments on a remote server\n",
        "- Avoid overloading remote servers with unnecessary data\n",
        "\n",
        "---\n",
        "\n",
        "## 📋 Prerequisites\n",
        "\n",
        "- Completed **Tutorial 1** (local MLflow setup)\n",
        "- At least one successful run in your local MLflow server\n",
        "- Access credentials to the remote MLflow server (username + password)\n",
        "- Understanding of the `mlruns/` and `mlartifacts/` directory structure\n",
        "\n",
        "---\n",
        "\n",
        "## 🔑 Key Concept: Why Re-run Instead of Transfer?\n",
        "\n",
        "MLflow doesn't have a \"copy run\" feature. Instead, we:\n",
        "\n",
        "1. **Experiment freely locally** (unlimited runs, no server load)\n",
        "2. **Identify the best model** (using local UI/metrics)\n",
        "3. **Re-run ONLY that model** on the remote server (with same params, data, model)\n",
        "\n",
        "This approach:\n",
        "- ✅ Keeps remote servers clean and organized\n",
        "- ✅ Reduces bandwidth and storage costs\n",
        "- ✅ Ensures reproducibility\n",
        "- ✅ Maintains complete experiment history locally\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setting Up Remote Server Credentials\n",
        "\n",
        "Before connecting to the remote server, you need to set up authentication.\n",
        "\n",
        "### 🔐 Set environment variables\n",
        "\n",
        "In your terminal (or add to your `.bashrc`/`.zshrc`):\n",
        "\n",
        "```bash\n",
        "export MLFLOW_TRACKING_USERNAME=\"your_username\"\n",
        "export MLFLOW_TRACKING_PASSWORD=\"your_password\"\n",
        "export MLFLOW_TRACKING_URI=\"https://mlflow-dev.fink-broker.org\"\n",
        "```\n",
        "\n",
        "⚠️ **Security Note**: Never hardcode credentials in your notebooks or scripts!\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verify environment variables are set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Check if credentials are set\n",
        "required_vars = [\"MLFLOW_TRACKING_USERNAME\", \"MLFLOW_TRACKING_PASSWORD\", \"MLFLOW_TRACKING_URI\"]\n",
        "\n",
        "for var in required_vars:\n",
        "    if var in os.environ:\n",
        "        print(f\"✅ {var} is set\")\n",
        "    else:\n",
        "        print(f\"❌ {var} is NOT set - please set it before continuing!\")\n",
        "        \n",
        "# Display the tracking URI (safe to show)\n",
        "if \"MLFLOW_TRACKING_URI\" in os.environ:\n",
        "    print(f\"\\n🔗 Remote server: {os.environ['MLFLOW_TRACKING_URI']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Identifying Your Best Local Run\n",
        "\n",
        "First, let's look at your local runs to identify which one to send to the remote server.\n",
        "\n",
        "### 📁 Understanding the Local Directory Structure\n",
        "\n",
        "Navigate to where you ran `mlflow server` in Tutorial 1. You should see:\n",
        "\n",
        "```\n",
        "your_directory/\n",
        "├── mlruns/              # Metadata\n",
        "│   └── <experiment_id>/\n",
        "│       └── <run_id>/\n",
        "└── mlartifacts/         # Actual artifacts\n",
        "    └── <experiment_id>/\n",
        "        └── <run_id>/\n",
        "```\n",
        "\n",
        "### 📸 Screenshot placeholder: Directory structure\n",
        "extract from tree \n",
        "\n",
        "```\n",
        "mlruns/\n",
        "├── 0 # default experiemnt\n",
        "│   └── meta.yaml\n",
        "├── 256835725489686937 # tutorial experiement\n",
        "│   ├── 159b8d88e56446dfb595b540960b99be # run\n",
        "│   │   ├── artifacts\n",
        "│   │   ├── meta.yaml\n",
        "│   │   ├── metrics\n",
        "│   │   │   ├── accuracy\n",
        "│   │   │   └── f1_score\n",
        "│   │   ├── outputs\n",
        "│   │   │   └── m-34aaeb7bdad14f93a3e76ed769f7bf18\n",
        "│   │   │       └── meta.yaml\n",
        "│   │   ├── params\n",
        "│   │   │   ├── learning_rate\n",
        "│   │   │   └── random_state\n",
        "│   │   └── tags\n",
        "│   │       ├── mlflow.runName\n",
        "│   │       ├── mlflow.source.name\n",
        "│   │       ├── mlflow.source.type\n",
        "│   │       └── mlflow.user\n",
        "│   ├── meta.yaml\n",
        "│   ├── models # model use for this run \n",
        "│   │   ├── m-34aaeb7bdad14f93a3e76ed769f7bf18\n",
        "│   │   │   ├── meta.yaml\n",
        "│   │   │   ├── metrics\n",
        "│   │   │   │   ├── accuracy\n",
        "│   │   │   │   └── f1_score\n",
        "│   │   │   ├── params\n",
        "│   │   │   │   ├── learning_rate\n",
        "│   │   │   │   └── random_state\n",
        "│   │   │   └── tags\n",
        "│   │   │       ├── mlflow.source.name\n",
        "│   │   │       ├── mlflow.source.type\n",
        "│   │   │       └── mlflow.user\n",
        "│   └── tags\n",
        "│       └── mlflow.experimentKind\n",
        "└── models\n",
        "mlartifacts/\n",
        "└── 256835725489686937\n",
        "    ├── d62f60d9ecde424ea0bdc30352bf7143\n",
        "    │   └── artifacts\n",
        "    │       ├── meta.json\n",
        "    │       ├── X_train.parquet\n",
        "    │       └── y_train.parquet\n",
        "    └── models\n",
        "        ├── m-34aaeb7bdad14f93a3e76ed769f7bf18\n",
        "        │   └── artifacts\n",
        "        │       ├── conda.yaml\n",
        "        │       ├── input_example.json\n",
        "        │       ├── MLmodel\n",
        "        │       ├── model.pkl\n",
        "        │       ├── python_env.yaml\n",
        "        │       ├── requirements.txt\n",
        "        │       └── serving_input_example.json\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔍 Find your experiment and run IDs\n",
        "\n",
        "You can find these either:\n",
        "1. **In the MLflow UI** (URL shows experiment and run IDs)\n",
        "2. **Programmatically** (as we did in Tutorial 1)\n",
        "3. **By browsing the file system**\n",
        "\n",
        "Let's do it programmatically:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "import pandas as pd\n",
        "\n",
        "# Connect to LOCAL MLflow server\n",
        "LOCAL_HOST = \"http://127.0.0.1\"\n",
        "LOCAL_PORT = 6969\n",
        "mlflow.set_tracking_uri(f\"{LOCAL_HOST}:{LOCAL_PORT}\")\n",
        "\n",
        "client = MlflowClient()\n",
        "\n",
        "# Get the experiment\n",
        "EXPERIMENT_NAME = \"tutorial\"  # From Tutorial 1\n",
        "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
        "\n",
        "if experiment is None:\n",
        "    print(f\"❌ Experiment '{EXPERIMENT_NAME}' not found!\")\n",
        "    print(\"Make sure you completed Tutorial 1 first.\")\n",
        "else:\n",
        "    print(f\"✅ Found experiment: {EXPERIMENT_NAME}\")\n",
        "    print(f\"📊 Experiment ID: {experiment.experiment_id}\")\n",
        "    \n",
        "    # Get all runs\n",
        "    runs = client.search_runs(experiment.experiment_id)\n",
        "    print(f\"📈 Total runs: {len(runs)}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View all runs and select the best one\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display all runs with their metrics\n",
        "run_data = []\n",
        "for run in runs:\n",
        "    run_data.append({\n",
        "        \"Run Name\": run.data.tags.get(\"mlflow.runName\", \"N/A\"),\n",
        "        \"Run ID\": run.info.run_id,\n",
        "        \"Learning Rate\": run.data.params.get(\"learning_rate\", \"N/A\"),\n",
        "        \"Accuracy\": run.data.metrics.get(\"accuracy\", \"N/A\"),\n",
        "        \"F1 Score\": run.data.metrics.get(\"f1_score\", \"N/A\"),\n",
        "        \"Status\": run.info.status\n",
        "    })\n",
        "\n",
        "runs_df = pd.DataFrame(run_data)\n",
        "print(\"📊 Available runs:\")\n",
        "display(runs_df.sort_values(\"Accuracy\", ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🎯 Select the run you want to send\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select the best run (highest accuracy in this case)\n",
        "# In practice, you might choose based on different criteria\n",
        "best_run = runs[0]  # Assuming sorted by best metric\n",
        "for run in runs:\n",
        "    acc = run.data.metrics.get(\"accuracy\", 0)\n",
        "    if acc >= best_run.data.metrics.get(\"accuracy\", 0):\n",
        "        best_run = run\n",
        "\n",
        "print(\"🏆 Selected run to send:\")\n",
        "print(f\"  - Name: {best_run.data.tags.get('mlflow.runName', 'N/A')}\")\n",
        "print(f\"  - Run ID: {best_run.info.run_id}\")\n",
        "print(f\"  - Accuracy: {best_run.data.metrics.get('accuracy', 'N/A')}\")\n",
        "print(f\"  - F1 Score: {best_run.data.metrics.get('f1_score', 'N/A')}\")\n",
        "\n",
        "# Store IDs for later use\n",
        "SELECTED_RUN_ID = best_run.info.run_id\n",
        "EXPERIMENT_ID = experiment.experiment_id\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Retrieving Artifacts from the Local Run\n",
        "\n",
        "Now we need to gather all the information from this run to reproduce it on the remote server.\n",
        "\n",
        "### 🗂️ Configure paths\n",
        "\n",
        "⚠️ **Important**: Update `root_dir` to where YOUR `mlflow server` was running!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# UPDATE THIS PATH to where you ran `mlflow server`\n",
        "# This directory should contain mlruns/ and mlartifacts/\n",
        "root_dir = Path().resolve().parent # Assumes parent directory, adjust if needed\n",
        "\n",
        "print(f\"📁 Root directory: {root_dir}\")\n",
        "print(f\"   Looking for mlruns/ and mlartifacts/...\")\n",
        "\n",
        "# Verify directories exist\n",
        "mlruns_dir = root_dir / \"mlruns\"\n",
        "mlartifacts_dir = root_dir / \"mlartifacts\"\n",
        "\n",
        "if mlruns_dir.exists():\n",
        "    print(f\"   ✅ Found mlruns/\")\n",
        "else:\n",
        "    print(f\"   ❌ mlruns/ not found! Update root_dir\")\n",
        "    \n",
        "if mlartifacts_dir.exists():\n",
        "    print(f\"   ✅ Found mlartifacts/\")\n",
        "else:\n",
        "    print(f\"   ❌ mlartifacts/ not found! Update root_dir\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 📦 Load training data from artifacts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build paths to the artifacts\n",
        "artifacts_path = mlartifacts_dir / EXPERIMENT_ID / SELECTED_RUN_ID / \"artifacts\"\n",
        "\n",
        "path_X = artifacts_path / \"X_train.parquet\"\n",
        "path_y = artifacts_path / \"y_train.parquet\"\n",
        "\n",
        "print(f\"📂 Artifacts path: {artifacts_path}\")\n",
        "\n",
        "# Load the data\n",
        "if path_X.exists() and path_y.exists():\n",
        "    X = pd.read_parquet(path_X)\n",
        "    y = pd.read_parquet(path_y)\n",
        "    print(f\"✅ Loaded training data:\")\n",
        "    print(f\"   - X shape: {X.shape}\")\n",
        "    print(f\"   - y shape: {y.shape}\")\n",
        "else:\n",
        "    print(\"❌ Training data not found in artifacts!\")\n",
        "    print(\"   Make sure you logged the data in Tutorial 1\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ⚙️ Load model parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load metadata (contains parameters)\n",
        "meta_path = artifacts_path / \"meta.json\"\n",
        "\n",
        "if meta_path.exists():\n",
        "    with open(meta_path, \"r\") as f:\n",
        "        metadata = json.load(f)\n",
        "    PARAMS = metadata['params']\n",
        "    print(f\"✅ Loaded parameters: {PARAMS}\")\n",
        "else:\n",
        "    print(\"❌ meta.json not found!\")\n",
        "    print(\"   Falling back to run parameters...\")\n",
        "    PARAMS = best_run.data.params\n",
        "    print(f\"   Parameters: {PARAMS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Generate Environment Dependencies\n",
        "\n",
        "The remote server needs to know which packages are required to run your preprocessing code.\n",
        "\n",
        "This project includes a utility to automatically extract dependencies from your code:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "sys.path.append(os.path.abspath(\"..\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mlflink.utils.env_utils import generate_requirements_txt_from_imports\n",
        "from importlib import resources\n",
        "\n",
        "# Get path to preprocessing module\n",
        "with resources.path(\"mlflink\", \"processing\") as module_path:\n",
        "    PKG_DIR = module_path\n",
        "\n",
        "print(f\"📦 Analyzing dependencies in: {PKG_DIR}\")\n",
        "\n",
        "# Generate requirements.txt\n",
        "dependencies_path = generate_requirements_txt_from_imports(\n",
        "    PKG_DIR, \n",
        "    \"/tmp/requirements.txt\", \n",
        "    include_self=False\n",
        ")\n",
        "\n",
        "print(f\"✅ Generated requirements.txt at: {dependencies_path}\")\n",
        "\n",
        "# Display the generated requirements\n",
        "print(\"\\n📋 Dependencies to be sent to remote server:\")\n",
        "with open(dependencies_path, \"r\") as f:\n",
        "    print(f.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 💡 Why This Matters\n",
        "\n",
        "The remote server (Fink) needs:\n",
        "1. ✅ Your trained model (for making predictions)\n",
        "2. ✅ Your preprocessing code (to prepare new data)\n",
        "3. ✅ Environment dependencies (to run your code)\n",
        "\n",
        "MLflow automatically handles (1), but we need to explicitly log (2) and (3).\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Re-run on Remote Server\n",
        "\n",
        "Now we have everything we need! Let's re-run the experiment on the remote server.\n",
        "\n",
        "### 🌐 Switch to remote tracking URI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from mlflow.models import infer_signature\n",
        "import numpy as np\n",
        "\n",
        "# Get remote server URL from environment\n",
        "# REMOTE_URI = os.environ.get(\"MLFLOW_TRACKING_URI\", \"https://mlflow-dev.fink-broker.org\")\n",
        "REMOTE_URI = \"https://mlflow-dev.fink-broker.org\"\n",
        "\n",
        "print(f\"🔄 Switching from local to remote server...\")\n",
        "print(f\"   Local:  {LOCAL_HOST}:{LOCAL_PORT}\")\n",
        "print(f\"   Remote: {REMOTE_URI}\")\n",
        "\n",
        "# Switch to remote server\n",
        "mlflow.set_tracking_uri(REMOTE_URI)\n",
        "mlflow.set_experiment(\"tutorial\")  # Use same experiment name\n",
        "\n",
        "client = MlflowClient()\n",
        "\n",
        "print(f\"✅ Connected to remote server!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🚀 Run the experiment on remote server\n",
        "\n",
        "This is almost identical to Tutorial 1, but with TWO critical additions for the remote server:\n",
        "1. Log the preprocessing code\n",
        "2. Log the requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"🚀 Starting run on REMOTE server...\\\\n\")\n",
        "\n",
        "with mlflow.start_run(run_name=f\"remote_LR_{PARAMS['learning_rate']}\"):\n",
        "    \n",
        "    # ==========================================\n",
        "    # 1. TRAIN MODEL (same as before)\n",
        "    # ==========================================\n",
        "    print(\"🏋️  Training model...\")\n",
        "    model = HistGradientBoostingClassifier(**PARAMS)\n",
        "    model.fit(X.values, y)\n",
        "    y_pred = model.predict(X.values)\n",
        "    print(\"✅ Model trained!\\\\n\")\n",
        "    \n",
        "    # ==========================================\n",
        "    # 2. LOG PARAMETERS (same as before)\n",
        "    # ==========================================\n",
        "    print(\"📝 Logging parameters...\")\n",
        "    mlflow.log_params(PARAMS)\n",
        "    \n",
        "    # ==========================================\n",
        "    # 3. LOG MODEL (same as before)\n",
        "    # ==========================================\n",
        "    print(\"💾 Logging model...\")\n",
        "    signature = infer_signature(X, y_pred)\n",
        "    mlflow.sklearn.log_model(\n",
        "        model,\n",
        "        artifact_path=\"model\",\n",
        "        signature=signature,\n",
        "        input_example=X.iloc[:1],\n",
        "    )\n",
        "    \n",
        "    # ==========================================\n",
        "    # 4. LOG METRICS (same as before)\n",
        "    # ==========================================\n",
        "    print(\"📊 Logging metrics...\")\n",
        "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
        "    mlflow.log_metric(\"precision\", precision_score(y, y_pred, zero_division=0))\n",
        "    mlflow.log_metric(\"recall\", recall_score(y, y_pred, zero_division=0))\n",
        "    mlflow.log_metric(\"f1_score\", f1_score(y, y_pred, zero_division=0))\n",
        "    \n",
        "    # ==========================================\n",
        "    # 5. LOG DATA (optional - be selective!)\n",
        "    # ==========================================\n",
        "    print(\"💿 Logging training data...\")\n",
        "    mlflow.log_table(X, \"X_train.parquet\")\n",
        "    mlflow.log_table(y, \"y_train.parquet\")\n",
        "    \n",
        "    # ==========================================\n",
        "    # 6. LOG METADATA (same as before)\n",
        "    # ==========================================\n",
        "    print(\"📋 Logging metadata...\")\n",
        "    meta_info = {\n",
        "        \"params\": PARAMS,\n",
        "        \"data_info\": {\n",
        "            \"n_samples\": X.shape[0],\n",
        "            \"n_features\": X.shape[1]\n",
        "        },\n",
        "        \"notes\": \"Run sent from local to remote server\",\n",
        "        \"original_run_id\": SELECTED_RUN_ID\n",
        "    }\n",
        "    with open(\"meta.json\", \"w\") as f:\n",
        "        json.dump(meta_info, f, indent=2)\n",
        "    mlflow.log_artifact(\"meta.json\")\n",
        "    \n",
        "    # ==========================================\n",
        "    # 7. LOG PREPROCESSING CODE NEW FOR REMOTE 🆕\n",
        "    # ==========================================\n",
        "    # This is CRITICAL for deployment! The remote server (Fink) needs your \n",
        "    # preprocessing code to transform new incoming data the same way you \n",
        "    # transformed your training data. Without this, the model won't work!\n",
        "    #\n",
        "    # Why we log the entire processing directory:\n",
        "    # - Other developers can reproduce your exact preprocessing pipeline\n",
        "    # - The Fink server can apply the same transformations to live data\n",
        "    # - Ensures consistency between training and production inference\n",
        "    # - Makes your model deployment fully reproducible\n",
        "    print(\"📦 Logging preprocessing code...\")\n",
        "    with resources.path(\"mlflink\", \"processing\") as preprocessing_path:\n",
        "        mlflow.log_artifacts(str(preprocessing_path), name=\"code\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 8. LOG REQUIREMENTS NEW FOR REMOTE 🆕\n",
        "    # ==========================================\n",
        "    # The requirements.txt file tells the remote server which Python packages\n",
        "    # are needed to run your preprocessing code. Without this, your code \n",
        "    # might fail due to missing dependencies!\n",
        "    #\n",
        "    # Why this matters:\n",
        "    # - Ensures the remote environment has all necessary libraries\n",
        "    # - Other developers know exactly which versions you used\n",
        "    # - Prevents \"works on my machine\" problems\n",
        "    # - Critical for the Fink server to execute your preprocessing pipeline\n",
        "    #\n",
        "    # Note: This only includes dependencies for preprocessing, not the model\n",
        "    # (MLflow handles model dependencies automatically)\n",
        "    print(\"📋 Logging dependencies...\")\n",
        "    mlflow.log_artifact(dependencies_path)\n",
        "    \n",
        "    print(\"\\\\n✅ Run completed successfully on REMOTE server!\")\n",
        "    print(f\"🔗 View at: {REMOTE_URI}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Verify the Remote Run\n",
        "\n",
        "Let's verify that everything was uploaded correctly:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query the remote server\n",
        "remote_experiment = client.get_experiment_by_name(\"tutorial\")\n",
        "remote_runs = client.search_runs(remote_experiment.experiment_id, max_results=5)\n",
        "\n",
        "print(f\"📊 Latest runs on remote server:\\\\n\")\n",
        "\n",
        "for i, run in enumerate(remote_runs[:3], 1):\n",
        "    print(f\"{i}. {run.data.tags.get('mlflow.runName', 'N/A')}\")\n",
        "    print(f\"   - Run ID: {run.info.run_id[:8]}...\")\n",
        "    print(f\"   - Accuracy: {run.data.metrics.get('accuracy', 'N/A')}\")\n",
        "    print(f\"   - Status: {run.info.status}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. What We Sent vs. What We Didn't\n",
        "\n",
        "### ✅ What we sent to the remote server:\n",
        "- Trained model (sklearn artifact)\n",
        "- Model parameters\n",
        "- Performance metrics\n",
        "- Training data (X and y) - optional\n",
        "- Preprocessing code (entire `processing/` directory)\n",
        "- Requirements.txt (dependencies)\n",
        "- Metadata (custom info)\n",
        "\n",
        "### 🙅🏿 What we didn't send:\n",
        "- All the failed/experimental runs\n",
        "- Intermediate debugging runs\n",
        "- Large datasets from experimentation\n",
        "- Temporary files\n",
        "\n",
        "This keeps the remote server clean and focused on production-ready models!\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Best Practices for Remote Runs\n",
        "\n",
        "### ✅ DO:\n",
        "- **Experiment extensively locally first** (unlimited runs)\n",
        "- **Send only your best/final models** to remote\n",
        "- **Include preprocessing code** (critical for deployment)\n",
        "- **Log dependencies** (requirements.txt)\n",
        "- **Use descriptive run names** (easier to find later)\n",
        "- **Add metadata** about the original local run\n",
        "\n",
        "### 🙅🏿 DON'T:\n",
        "- **Send every experimental run** (overloads server)\n",
        "- **Log huge datasets** unless absolutely necessary\n",
        "- **Forget to include preprocessing code** (model won't work without it)\n",
        "- **Skip the requirements.txt** (environment issues)\n",
        "- **Send runs with errors or incomplete training**\n",
        "\n",
        "### 💡 Recommended Workflow:\n",
        "\n",
        "```\n",
        "1. Local: Run 50 experiments with different parameters\n",
        "2. Local: Identify the best 1-3 models\n",
        "3. Local: Do a final run with those params + full data logging\n",
        "4. Remote: Send ONLY those 1-3 final runs\n",
        "5. Remote: Verify they work correctly\n",
        "```\n",
        "\n",
        "This approach:\n",
        "- Maximizes your experimentation freedom locally\n",
        "- Minimizes remote server load\n",
        "- Keeps remote experiments organized and meaningful\n",
        "- Reduces costs (bandwidth, storage)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  <img src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExeXd2ZTNscDZtbm1jbDB2dDJveGp2ZWdtMmhsMDg0MmdvdnpncmJzZSZlcD12MV9zdGlja2Vyc19zZWFyY2gmY3Q9cw/xUPGchCSJlq3NzwLyU/giphy.gif\" width=\"50\" height=\"50\"> WHY  Steps 7 & 8 Are Essential for Remote Deployment\n",
        "\n",
        "When you send a model to the Fink server, you're not just sending the trained model weights. \n",
        "For the model to work in production, Fink needs:\n",
        "\n",
        "1. **Your preprocessing code** (Step 7):\n",
        "   - The server receives raw alert data\n",
        "   - It needs to transform this data exactly as you did during training\n",
        "   - Your `make_cut()`, `raw2clean()`, `run_sherlock()`, and `make_X()` functions\n",
        "   - Without this, the model would receive incorrectly formatted data\n",
        "\n",
        "2. **Your dependencies** (Step 8):\n",
        "   - Your preprocessing code might use specific libraries (pandas, numpy, lasair, etc.)\n",
        "   - The server needs to know which versions to install\n",
        "   - Prevents runtime errors due to missing or incompatible packages\n",
        "\n",
        "**Real-world scenario:**\n",
        "- You train a model locally with your preprocessing pipeline\n",
        "- Fink receives new alerts and needs to classify them\n",
        "- Fink loads your model AND your preprocessing code\n",
        "- For each alert: `raw data → your preprocessing → your model → prediction`\n",
        "- Other scientists can also download and run your complete pipeline\n",
        "\n",
        "**Without these steps**, your model would be useless on the remote server! 🚫"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎓 Summary\n",
        "\n",
        "<iframe src=\"https://giphy.com/embed/S3nZ8V9uemShxiWX8g\" width=\"40\" height=\"40\" style=\"\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>Congratulations! You've learned : <iframe src=\"https://giphy.com/embed/8fftcK2D4PK6XCs2P0\" width=\"60\" height=\"60\" style=\"\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n",
        "\n",
        "✅ How to identify your best local runs  \n",
        "✅ How to retrieve artifacts from local MLflow storage  \n",
        "✅ How to generate environment dependencies automatically  \n",
        "✅ How to re-run experiments on a remote server  \n",
        "✅ Best practices for avoiding server overload  \n",
        "✅ The difference between local experimentation and remote deployment  \n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 Next Steps\n",
        "\n",
        "In **Tutorial 3** ??? (optional), you'll learn how to:\n",
        "<!-- - Customize the preprocessing pipeline for your data\n",
        "- Replace the example model with your own\n",
        "- Adapt this template for your specific project -->\n",
        "\n",
        "---\n",
        "\n",
        "## 🆘 Troubleshooting  <iframe src=\"https://giphy.com/embed/PnpkimJ5mrZRe\" width=\"200\" height=\"200\" style=\"\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n",
        "\n",
        "### Problem: Authentication failed\n",
        "**Solution**: Double-check your environment variables are set correctly. Try logging out and back in.\n",
        "\n",
        "### Problem: Can't find local artifacts\n",
        "**Solution**: Make sure `root_dir` points to where you ran `mlflow server`. Look for `mlruns/` and `mlartifacts/` folders.\n",
        "\n",
        "### Problem: \"Permission denied\" on remote server\n",
        "**Solution**: Verify your username has write access. Contact server administrator if needed.\n",
        "\n",
        "### Problem: Missing preprocessing code on remote\n",
        "**Solution**: Make sure you logged the preprocessing directory with `mlflow.log_artifacts()`\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
